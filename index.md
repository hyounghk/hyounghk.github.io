
### About Me
I am an assistant professor at POSTECH [GSAI](https://ai.postech.ac.kr/)/[CSE](https://cse.postech.ac.kr/), leading [Language & Intelligence Lab (LIL)](https://sites.google.com/view/language-intelligence-lab) under [POSTECH NLP Group](https://nlp.postech.ac.kr/). Before joining POSTECH, I was an assistant professor at UNIST AIGS/CSE. I earned my PhD from UNC Chapel Hill, where I was advised by Prof. [Mohit Bansal](http://www.cs.unc.edu/~mbansal). I also worked with Prof. [Henry Fuchs](http://henryfuchs.web.unc.edu/) on AR applications.


### Publications
* **Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions**<br>
Jihyoung Jang\*, Minwook Bae\*, Minji Kim, Dilek Hakkani-Tur, and <ins>Hyounghun Kim</ins><br>
Proceedings of [ACL 2025](https://2025.aclweb.org/). [[pdf](https://arxiv.org/abs/2506.00421)]

* **Collective Critics for Creative Story Generation**<br>
Minwook Bae, and <ins>Hyounghun Kim</ins><br>
Proceedings of [EMNLP 2024](https://2024.emnlp.org/). [[pdf](https://arxiv.org/abs/2410.02428)]

* **Mixed-Session Conversation with Egocentric Memory**<br>
Jihyoung Jang, Taeyoung Kim, and <ins>Hyounghun Kim</ins><br>
Findings of [EMNLP 2024](https://2024.emnlp.org/). [[pdf](https://arxiv.org/abs/2410.02503)] [[website](https://mixed-session.github.io/)]

* **Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations**<br>
Jihyoung Jang, MinSeong Boo, and <ins>Hyounghun Kim</ins><br>
Proceedings of [EMNLP 2023](https://2023.emnlp.org/). [[pdf](https://arxiv.org/abs/2310.13420)] [[website](https://conversation-chronicles.github.io/)]

* **Sound of Story: Multi-modal Storytelling with Audio**<br>
Jaeyeon Bae\*, Seokhoon Jeong\*, Seokun Kang, Namgi Han, Jae-Yon Lee, <ins>Hyounghun Kim</ins>, and Taehwan Kim<br> 
Findings of [EMNLP 2023](https://2023.emnlp.org/). [[pdf](https://arxiv.org/abs/2310.19264)]

* **CoSIm: Commonsense Reasoning for Counterfactual Scene Imagination**<br>
<ins>Hyounghun Kim</ins>\*, Abhay Zala\*, and Mohit Bansal<br>
Proceedings of [NAACL 2022](https://2022.naacl.org/). [[pdf](https://arxiv.org/abs/2207.03961)]

* **On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets**<br>
<ins>Hyounghun Kim</ins>, Aishwarya Padmakumar, Di Jin, Mohit Bansal, and Dilek Hakkani-Tur<br>
[Insights Workshop](https://insights-workshop.github.io/), ACL 2022. [[pdf](https://arxiv.org/abs/2205.09249/)]

* **CAISE: Conversational Agent for Image Search and Editing**  
<ins>Hyounghun Kim</ins>, Doo Soon Kim, Seunghyun Yoon, Franck Dernoncourt, Trung Bui, and Mohit Bansal  
Proceedings of [AAAI 2022](https://aaai.org/Conferences/AAAI-22/). [[pdf](https://arxiv.org/abs/2202.11847/)][[code](https://github.com/hyounghk/CAISE)]

* **NDH-Full: Learning and Evaluating Navigational Agents on Full-Length Dialogue**  
<ins>Hyounghun Kim</ins>, Jialu Li, and Mohit Bansal  
Proceedings of [EMNLP 2021](https://2021.emnlp.org/). [[pdf](https://aclanthology.org/2021.emnlp-main.518/)][[code](https://github.com/hyounghk/NDH-FULL)]

* **Continuous Language Generative Flow**  
Zineng Tang, Shiyue Zhang, <ins>Hyounghun Kim</ins>, and Mohit Bansal  
Proceedings of [ACL 2021](https://2021.aclweb.org/). [[pdf](https://aclanthology.org/2021.acl-long.355/)][[code](https://github.com/zinengtang/ContinuousFlowNL)]

* **FixMyPose: Pose Correctional Captioning and Retrieval**  
<ins>Hyounghun Kim</ins>\*, Abhaysinh Zala\*, Graham Burri, and Mohit Bansal  
Proceedings of [AAAI 2021](https://aaai.org/Conferences/AAAI-21/). [[pdf](https://arxiv.org/abs/2104.01703)][[code](https://github.com/hyounghk/FixMyPose)]

* **ArraMon: A Joint Navigation-Assembly Instruction Interpretation Task in Dynamic Environments**  
<ins>Hyounghun Kim</ins>, Abhaysinh Zala, Graham Burri, Hao Tan, and Mohit Bansal  
Findings of [EMNLP 2020](https://2020.emnlp.org/). [[pdf](http://arxiv.org/abs/2011.07660)][[code](https://github.com/hyounghk/ArraMon)]

* **Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA**  
<ins>Hyounghun Kim</ins>, Zineng Tang, and Mohit Bansal  
Proceedings of [ACL 2020](https://acl2020.org/), Seattle, WA. [[pdf](https://arxiv.org/abs/2005.06409)][[code](https://github.com/hyounghk/VideoQADenseCapFrameGate-ACL2020)]

* **Modality-Balanced Models for Visual Dialogue**  
<ins>Hyounghun Kim</ins>, Hao Tan, and Mohit Bansal  
Proceedings of [AAAI 2020](https://aaai.org/Conferences/AAAI-20/), New York, NY. [[pdf](https://arxiv.org/abs/2001.06354)]

* **Improving Visual Question Answering by Referring to Generated Paragraph Captions**  
<ins>Hyounghun Kim</ins> and Mohit Bansal  
Proceedings of [ACL 2019](http://www.acl2019.org/), Florence, Italy (short paper). [[pdf](https://arxiv.org/abs/1906.06216)]  
([ACL Best Short Paper Nomination](http://www.acl2019.org/EN/nominations-for-acl-2019-best-paper-awards.xhtml))

* **Development of Augmented Reality Applications in Otolaryngology-Head and Neck Surgery**  
Austin S. Rose, <ins>Hyounghun Kim</ins>, Henry Fuchs, and Jan-Michael Frahm  
The Laryngoscope, Jul. 2019. [[pdf](https://onlinelibrary.wiley.com/doi/pdf/10.1002/lary.28098)]

* **Towards Fully Mobile 3D Face, Body, and Environment Capture Using Only Head-worn Cameras**   
Young-Woon Cha, True Price, Zhen Wei, Xinran Lu, Nicholas Rewkowski, Rohan Chabra, Zihe Qin, <ins>Hyounghun Kim</ins>, Zhaoqi Su, Yebin Liu, Adrian Ilie, Andrei State, Zhenlin Xu, Jan-Michael Frahm, and Henry Fuchs  
IEEE Transactions on Visualization and Computer Graphics (TVCG), Vol. 24, November, 2018. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8458443)]

